---
layout: post
title:  "[GRL Book 정리] Chapter 4. Multi-relational Data and Knowledge Graphs"
date:   2021-10-5 22:00
categories: [Others]
use_math: true
comments: true
---

![intro](https://raw.githubusercontent.com/HiddenBeginner/hiddenbeginner.github.io/master/static/img/_posts/2021-08-25-grl_book_ch3/earth-network.jpg){: .center}
<center>사진 출처: <a href="#ref1">[1]</a></center>

# <center>Chapter 4. Multi-relational Data and Knowledge Graphs</center>

[Graph Representation Learning Book](https://www.cs.mcgill.ca/~wlh/grl_book/) 읽고 정리하기 시리즈 중 여섯 번째 이야기. 부디 완주하게 기도해주세요 !

<br>

---

노드와 노드 사이의 관계가 여러 개인 그래프를 multi-relational 그래프라고 한다. 즉, Multi-relational 그래프 $\mathcal{G}=(\mathcal{V}, \mathcal{E}, \mathcal{R})$의 하나의 엣지는 튜플 $(u, \tau, v) \in \mathcal{V}\times\mathcal{R}\times\mathcal{V}$로 정의되며 노드 $u$와 노드 $v$가 관계 $\tau$에 대해 연결되어 있다는 것을 의미한다. Multi-relational 그래프를 `knowledge graph`라고 부르기도 한다.  이번 챕터에서는 Multi-relational 그래프 안의 노드를 임베딩하는 방법에 대해 알아본다.

<br>

# 4.1 Reconstructing Multi-relational Data
하나의 관계만 다루는 그래프에서 노드 임베딩을 하는 방법은 챕터 $3$에서 자세하게 다뤄보았다. 노드 임베딩에 필요한 요소가 세 가지 있었다. 바로 디코더, 손실 함수, 그리고 유사도 행렬이다. 디코더는 두 노드 $u, v$의 임베딩 벡터 $\mathbf{z}_u, \mathbf{z}_v\in\mathbb{R}^d$를 입력 받아서 두 노드 사이의 그래프 통계량을 출력해주는 함수였다.  해당 그래프 통계량은 두 노드 사이의 유사도 $\mathbf{S}[u, v]$이었다. 그리고 디코더의 출력값과 실제 유사도 사이의 손실을 최소화해주는 임베딩 벡터를 찾는 것이 우리의 목표였다.<br><br>

한편 Multi-relational 그래프에서는 관계의 종류까지 반영해서 노드들을 임베딩시켜야 할 것이다. 따라서 이 경우 디코더는 두 노드의 임베딩 벡터와 관계의 종류까지 입력 받아서 해당 관계에 대한 유사도를 출력해준다. 즉, $\text{DEC}:\mathbb{R}^d\times\mathcal{R}\times\mathbb{R}^d\rightarrow \mathbb{R}$인 함수이다. 가장 간단한 노드 임베딩 방법인 `RESCAL`은 다음 디코더를 사용한다.

$$\text{DEC}(\mathbf{z}_u,\tau,\mathbf{z}_v)=\mathbf{z}_u^\top\mathbf{R}_\tau\mathbf{z}_v, \quad \quad (4.1)$$

<br>

여기서 $\mathbf{R}\_\tau \in \mathbb{R}^{d\times d}$는 관계 $\tau$에 대한 학습 가능한 가중치 행렬이다. 만약 유사도 행렬로 인접행렬로 사용하고, 손실 함수로 오차 제곱을 사용한다면

$$\begin{matrix}
\mathcal{L}&=&\sum\limits_{u\in\mathcal{V}}\sum\limits_{v\in\mathcal{V}}\sum\limits_{\tau\in\mathcal{R}}\lVert\text{DEC}(\mathbf{z}_u,\tau,\mathbf{z}_v)-\mathcal{A}[u,\tau,v] \rVert^2& \quad \quad (4.2) \\
& = & \sum\limits_{u\in\mathcal{V}}\sum\limits_{v\in\mathcal{V}}\sum\limits_{\tau\in\mathcal{R}}\lVert \mathbf{z}_u^\top\mathbf{R}_\tau\mathbf{z}_v - \mathcal{A}[u,\tau,v] \rVert^2, & \quad \quad(4.3)
\end{matrix}$$

<br>

여기서 $\mathcal{A}\in\mathbb{R}^{\mid \mathcal{V} \mid \times \mid \mathcal{R} \mid \times \mid \mathcal{V} \mid}$은 multi-relational 그래프에 대응하는 인접 텐서이다. 이번 챕터의 남은 부분에서는 multi-relational 그래프에서의 노드 임베딩을 위한 손실 함수와 디코더에 대해 알아볼 것이다. 유사도 텐서로는 인접 텐서를 사용할 것이다.

<br>

---

# 4.2 Loss Function
**Coming soon!**

<br>

---

## 참고문헌
<p id="ref1">[1] <a href="https://pixabay.com/ko/illustrations/%ec%a7%80%ea%b5%ac-%ed%9a%8c%eb%a1%9c%eb%a7%9d-3537401/" target="_blank">https://pixabay.com/ko/illustrations/지구-회로망-3537401/</a></p>
<p id="ref2">[2] Hamilton, William L.,Graph Representation Learning, <i>Synthesis Lectures on Artificial Intelligence and Machine Learning</i>, 14, pp.1-159</p>
<p id="ref3">[3] <a href="http://web.stanford.edu/class/cs224w/" target="_blank">CS224W: Machine Learning with Graphs</a></p>
